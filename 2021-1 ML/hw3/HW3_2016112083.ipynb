{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW3_DT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrztCN_HFpuD"
      },
      "source": [
        "class Node:\n",
        "    \"\"\"\n",
        "    class Node\n",
        "    represents a node in a tree\n",
        "    its left branch represents a subset of DATA that meet “COLUMN < VALUE” and the right branch represents “COLUMN >= VALUE”.\n",
        "\n",
        "    <members>\n",
        "    column: features of data to be splitted on\n",
        "    value: value of data of feature to be splited on\n",
        "    dataset: dataset which to be spliited and has been splited before\n",
        "\n",
        "    depth: depth of node in a tree\n",
        "    left : pointer to left node\n",
        "    right: pointer to right node\n",
        "\n",
        "    isLeaf: boolean value which represent that this node is wether a leaf or not.\n",
        "            True -> it is a leaf node, False -> not a leaf node\n",
        "\n",
        "    <methods>\n",
        "\n",
        "    leaf(self) : leafify(mark this node as a leaf) this node\n",
        "    print_node(self): print the node information depends on two cases\n",
        "                    if this node is not a leaf node-> (XCOLUMN, VALUE). ex) (X1, 4.12346)\n",
        "                    if this node is a leaf node -> Labele that this tree has decided. ex) (0)\n",
        "    count_labels : method for leaf node.  count numbers of labels in the given node`s dataset.\n",
        "                    returns a label value which appear the most in the given node`s dataset\n",
        "    \"\"\"    \n",
        "    def __init__(self, column, value, dataset):\n",
        "        self.column= column\n",
        "        self.value = value\n",
        "        self.dataset = dataset\n",
        "\n",
        "        self.depth = None\n",
        "        self.left = None\n",
        "        self.right = None\n",
        "        \n",
        "        self.isLeaf = False\n",
        "\n",
        "    def leaf(self):\n",
        "        \"\"\"leaf(self) : leafify(mark this node as a leaf) this node\"\"\"\n",
        "        self.isLeaf = True\n",
        "        self.left = None\n",
        "        self.right = None\n",
        "    \n",
        "    def print_node(self):\n",
        "        \"\"\"\n",
        "        print_node(self): print the node information depends on two cases\n",
        "                  if this node is not a leaf node-> (XCOLUMN, VALUE). ex) (X1, 4.12346)\n",
        "                  if this node is a leaf node -> Labele that this tree has decided. ex) (0)\n",
        "        \"\"\"\n",
        "\n",
        "        \n",
        "        space = \"\"\n",
        "        \n",
        "        # case not a leaf node\n",
        "        if not self.isLeaf:\n",
        "            space += (self.depth - 1) * \"  \"  # add spaces according to depth of this node\n",
        "            print(\"%s(X%d, %f)\" % (space, self.column + 1, self.value))\n",
        "        # case leaf node\n",
        "        else:\n",
        "            space += (self.depth) * \"  \" # add spaces according to depth of this node\n",
        "            print(\"%s(%d)\"% (space, self.count_labels()))\n",
        "    \n",
        "    def count_labels(self):\n",
        "        \"\"\"\n",
        "        count_labels : method for leaf node.  count numbers of labels in the given node`s dataset.\n",
        "                returns a label value which appear the most in the given node`s dataset\n",
        "        \"\"\"\n",
        "        temp =[]\n",
        "\n",
        "        # put all labels of data\n",
        "        for data in self.dataset:\n",
        "            temp.append(data[-1])\n",
        "\n",
        "        min = -1\n",
        "        labels = list(set(temp))\n",
        "        \n",
        "        # for every labele appeared in this data\n",
        "        for i in range(len(labels)):\n",
        "\n",
        "            # count the appearance\n",
        "            cnt = temp.count(labels[i])\n",
        "            \n",
        "            # save the most appeared label as a return value\n",
        "            if cnt > min:\n",
        "                min = cnt\n",
        "                final_label = labels[i]\n",
        "\n",
        "        return final_label\n",
        "\n",
        "\n",
        "def gini_impurity(group_A, group_B):\n",
        "    \n",
        "    \"\"\" \n",
        "    Calculate the Gini impurity (a.k.a Gini index) of two groups of dataset.(left and right)\n",
        "    \n",
        "    \"\"\"\n",
        "    # variables initialization\n",
        "    num_A = len(group_A)\n",
        "    num_B = len(group_B)\n",
        "    num_total = num_A + num_B\n",
        "\n",
        "    table_A = []\n",
        "    table_B = []\n",
        "    labels = []\n",
        "\n",
        "    # save labels info into each group`s list        \n",
        "    for data in group_A:\n",
        "        labels.append(data[-1])\n",
        "        table_A.append(data[-1])\n",
        "    for data in group_B:\n",
        "        labels.append(data[-1])\n",
        "        table_B.append(data[-1])\n",
        "\n",
        "    # variable which contains all the labels appeared among two datasets\n",
        "    labels = list(set(labels))\n",
        "    \n",
        "\n",
        "\n",
        "    if num_A == 0:      # avoid devide by zero\n",
        "        gini_A = 0\n",
        "    else:\n",
        "        gini_A = 1      # calculate gini index for group A\n",
        "        for label in labels:\n",
        "            term = (table_A.count(label) / num_A) ** 2\n",
        "            gini_A -= term\n",
        "           \n",
        "    if num_B == 0:      # avoid devide by zero\n",
        "        gini_B = 0\n",
        "    else:\n",
        "        gini_B = 1       # calculate gini index for group B\n",
        "        for label in labels:\n",
        "            term = (table_B.count(label) / num_B) ** 2\n",
        "            gini_B -= term\n",
        "\n",
        "    # calculate final gini index between two groups and return\n",
        "    gini = gini_A * (num_A / num_total) + gini_B * (num_B / num_total)\n",
        "\n",
        "    return gini\n",
        "\n",
        "\n",
        "def split(dataset):\n",
        "    \"\"\"\n",
        "    helper function of recursive_split.\n",
        "    split dataset into two groups by a combination of best feature and value. \n",
        "    return a node which has splitted datasets.(the combination of which yields purest two dataset in terms of labels by using gini_impurity function )\n",
        "    \"\"\"\n",
        "\n",
        "    # initialize variables\n",
        "    node = Node(0,0,[])\n",
        "    min_gini = 100000;\n",
        "    \n",
        "    # for every featrues(columns) in the given dataset... (except label column)\n",
        "    for feature in range(len(dataset[0]) - 1):\n",
        "        # for every data in the given dataset...\n",
        "        for data in dataset:\n",
        "            group_A = []\n",
        "            group_B = []\n",
        "\n",
        "            # define a thresh for this iteraation which is a combination of COLUMN and VALUE\n",
        "            thresh = data[feature]\n",
        "\n",
        "            # split into two groups\n",
        "            for i in range(len(dataset)):\n",
        "                if dataset[i][feature] < thresh:\n",
        "                    group_A.append(dataset[i])\n",
        "                elif dataset[i][feature] >= thresh:\n",
        "                    group_B.append(dataset[i])\n",
        "            # calculate gini_impurity of this divide\n",
        "            cur_gini = gini_impurity(group_A, group_B)\n",
        "            \n",
        "            # if the gini_impurity is lowest so far, save it and continue\n",
        "            if cur_gini < min_gini:\n",
        "                min_gini = cur_gini\n",
        "                node.column = feature\n",
        "                node.value = thresh\n",
        "                node.dataset = [group_A,group_B]\n",
        "\n",
        "            # if the gini impurity tie\n",
        "            elif cur_gini == min_gini:\n",
        "\n",
        "                # choose the COLUMN and the VALUE that lead to the most balanced split,\n",
        "                # i.e., the absolute different between size(DATA) of the left child and size(DATA) of the right child should be minimized.\n",
        "                # If tie again for the balance, just pass this iteration.\n",
        "                cur_diff = abs(len(group_A) - len(group_B))\n",
        "                min_diff = abs(len(node.dataset[0]) - len(node.dataset[1]))\n",
        "                if cur_diff < min_diff:\n",
        "                    min_gini = cur_gini\n",
        "                    node.column = feature\n",
        "                    node.value = thresh\n",
        "                    node.dataset = [group_A,group_B]\n",
        "                \n",
        "    return node\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def recursive_split(node):\n",
        "    \n",
        "    \"\"\"\n",
        "    # This function will be recursively called.\n",
        "    # You can define your own helper functions to program this function.\n",
        "    # This function will be the most complicated function in this homework.\n",
        "\n",
        "    Recursively split nodes untill it met some conditions\n",
        "    1. if either of each group consist of zero data, then make the next left and right nodes to be leaf with data it got so far.\n",
        "    2. if current node reaches  max depth , make next nodes to be leafs(groupA for left, group B for right)\n",
        "    3. check if left group(group A) is big enough than min_samples_split. \n",
        "        3-1) if it has smaller number of data, then make left child as a leaf\n",
        "        3-2) otherwise create(split) and add left node by recursively.\n",
        "    4. do the same thing with 3-1~3-2 for right group\n",
        "    \"\"\"\n",
        "    group_A = node.dataset[0]\n",
        "    group_B = node.dataset[1]\n",
        "\n",
        "     #1. if either of each group consist of zero data, then make the next left and right nodes to be leaf with data it got so far.\n",
        "     # if group A has no data\n",
        "    if len(group_A) == 0:\n",
        "        left_leaf =  Node(node.column, node.value, group_B)\n",
        "        left_leaf.depth = node.depth  # for a leaf, no increase depth value\n",
        "        left_leaf.leaf()              # leafify left branch\n",
        "        \n",
        "        right_leaf = Node(node.column, node.value, group_B)\n",
        "        right_leaf.depth= node.depth     # for a leaf, no increase depth value\n",
        "        right_leaf.leaf()                # leafify right branch\n",
        "        \n",
        "        node.left = left_leaf\n",
        "        node.right = right_leaf\n",
        "        return;\n",
        "    \n",
        "     #1. if either of each group consist of zero data, then make the next left and right nodes to be leaf with data it got so far.\n",
        "     # if group B has no data\n",
        "    elif len(group_B) == 0:\n",
        "        left_leaf =  Node(node.column, node.value, group_A)\n",
        "        left_leaf.depth = node.depth    # for a leaf, no increase depth value\n",
        "        left_leaf.leaf()                 # leafify left branch\n",
        "        \n",
        "        right_leaf = Node(node.column, node.value, group_A)\n",
        "        right_leaf.depth= node.depth    # for a leaf, no increase depth value\n",
        "        right_leaf.leaf()               # leafify right branch\n",
        "        \n",
        "        node.left = left_leaf\n",
        "        node.right = right_leaf\n",
        "        return;\n",
        "\n",
        "    # 2. if we reach  max depth , make next nodes to be leafs(groupA for left, group B for right)\n",
        "    if node.depth >= max_depth:\n",
        "        \n",
        "        # leafify left and right child\n",
        "        left_leaf =  Node(node.column, node.value, group_A)\n",
        "        left_leaf.depth = node.depth\n",
        "        left_leaf.leaf()\n",
        "        \n",
        "        right_leaf = Node(node.column, node.value, group_B)\n",
        "        right_leaf.depth=node.depth\n",
        "        right_leaf.leaf()\n",
        "\n",
        "\n",
        "        node.left = left_leaf\n",
        "        node.right= right_leaf\n",
        "        \n",
        "        return;\n",
        "    # 3. check if left group(group A) is big enough than min_samples_split. \n",
        "    # 3-1) if it has smaller number of data, then make left child as a leaf\n",
        "    if len(group_A) <= min_samples_split:\n",
        "        left_leaf = Node(node.column, node.value, group_A)\n",
        "        left_leaf.depth = node.depth\n",
        "        left_leaf.leaf()\n",
        "\n",
        "        node.left= left_leaf\n",
        "    \n",
        "    # 3-2) otherwise add left node by recursively.\n",
        "    else:\n",
        "        left_node = split(group_A)\n",
        "        left_node.depth = node.depth + 1 # add depth value because next left node is not a leaf \n",
        "        node.left = left_node\n",
        "\n",
        "        recursive_split(left_node)      # recursively perform these sequences\n",
        "\n",
        "\n",
        "\n",
        "    # 4. do the same thing with 3-1~3-2 for right group\n",
        "    if len(group_B) <= min_samples_split:\n",
        "        right_leaf = Node(node.column, node.value, group_B)\n",
        "        right_leaf.depth = node.depth\n",
        "        right_leaf.leaf()\n",
        "\n",
        "        node.right = right_leaf\n",
        "    else:\n",
        "        right_node = split(group_B)\n",
        "        right_node.depth = node.depth + 1   # add depth value because next left node is not a leaf \n",
        "        node.right = right_node             \n",
        "\n",
        "        recursive_split(right_node)         # recursively perform these sequences\n",
        "\n",
        "def my_tree(dataset):\n",
        "    \"\"\"\n",
        "    # This function won't be long. Prepare recursive splits and initiate them.\n",
        "    build tree using recursive_split method.\n",
        "    returns a root which represents a decision tree.\n",
        "    \"\"\"\n",
        "  # split the initial root node\n",
        "    root = split(dataset)\n",
        "\n",
        "  # set depth value for root node\n",
        "    root.depth = 1\n",
        "  \n",
        "  # recursively build tree\n",
        "    recursive_split(root)\n",
        "  \n",
        "    return root\n",
        "\n",
        "def print_tree(node):\n",
        "    \"\"\"\n",
        "    print the trained tree in the depth-first manner. refer to the lecture slides.\n",
        "    pre-order traverse\n",
        "    \"\"\"\n",
        "    if node is not None:\n",
        "        node.print_node()\n",
        "        print_tree(node.left)\n",
        "        print_tree(node.right)\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_pUIsHi2ZDo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81af5b2c-3145-4321-dba9-32a9adba4a36"
      },
      "source": [
        "\n",
        "# datasets\n",
        "dataset = [ [2.2343124,1.123123,0],\n",
        "            [1.43523,1.54245,0],\n",
        "            [3.53467889,2.234987,0],\n",
        "            [3.1249876,2.09237512893,0],\n",
        "            [2.1238756,9.3253154,1],\n",
        "            [7.0981274,3.89074,1],\n",
        "            [1.129875,3.0987234,0],\n",
        "            [7.0897345,0.089745,1],\n",
        "            [6.0987214,3.0978214,1],\n",
        "            [6.1325,3.98763,1],\n",
        "            [1.35765,2.43663,0],\n",
        "            [2.345,3.3456,0],\n",
        "            [0.2345,1.4356,0],\n",
        "            [2.4356,5.67534,0],\n",
        "            [5.234,5.23465,1],\n",
        "            [4.12346,2.975,1],\n",
        "            [2.5467,4.72345,0],\n",
        "            [8.4612,1.6269,1],\n",
        "            [5.215690,2.5362,1],\n",
        "            [4.762,1.76567,1]\n",
        "          ]\n",
        "\n",
        "# configure parameters\n",
        "max_depth = 1\n",
        "min_samples_split = 2\n",
        "\n",
        "# codes for building tree and print!\n",
        "tree = my_tree(dataset)\n",
        "\n",
        "print(\"Decision Tree\")\n",
        "print(\"max_depth : %d\" % (max_depth))\n",
        "print(\"min_samples_split: %d\" % (min_samples_split))\n",
        "print()\n",
        "print_tree(tree)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decision Tree\n",
            "max_depth : 1\n",
            "min_samples_split: 2\n",
            "\n",
            "(X1, 4.123460)\n",
            "  (0)\n",
            "  (1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dQkwQzVRWEs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}