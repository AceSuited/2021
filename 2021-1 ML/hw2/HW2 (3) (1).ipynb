{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVvo3D7wXNP-"
      },
      "source": [
        "#Q1\n",
        "\"\"\"\n",
        "We use our custom function to approximate the sine function.\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import math\n",
        "\n",
        "\n",
        "class CustomFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        ctx.save_for_backward(input)\n",
        "        return 0.5 * (5 * input ** 3 - 3 * input)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, = ctx.saved_tensors\n",
        "        return [FILL ME]\n",
        "\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
        "y = torch.sin(x) # We approximate this sine function.\n",
        "\n",
        "# In our model, we have 4 weights to train: y = a + b * P3(c + d * x).\n",
        "# These weights need to be initialized.\n",
        "# Setting requires_grad=True indicates that we want to compute gradients with\n",
        "# respect to these Tensors during the backward pass.\n",
        "a = torch.full((), 0.0, device=device, dtype=dtype, requires_grad=True)\n",
        "b = torch.full((), -1.0, device=device, dtype=dtype, requires_grad=True)\n",
        "c = torch.full((), 0.0, device=device, dtype=dtype, requires_grad=True)\n",
        "d = torch.full((), 0.3, device=device, dtype=dtype, requires_grad=True)\n",
        "\n",
        "learning_rate = 5e-6\n",
        "for t in range(2000):\n",
        "    P3 = CustomFunction.apply\n",
        "\n",
        "    # Forward pass: predict y.\n",
        "    # P3 using our custom backward function.\n",
        "    y_pred = a + b * P3(c + d * x)\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = (y_pred - y).pow(2).sum()\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    # Use autograd to compute the backward pass.\n",
        "    [FILL ME]\n",
        "\n",
        "    # Update weights using gradient descent\n",
        "    with torch.no_grad():\n",
        "        [FILL ME]\n",
        "        [FILL ME]\n",
        "        [FILL ME]\n",
        "        [FILL ME]\n",
        "\n",
        "        # Manually zero the gradients after updating weights\n",
        "        a.grad = [FILL ME]\n",
        "        b.grad = [FILL ME]\n",
        "        c.grad = [FILL ME]\n",
        "        d.grad = [FILL ME]\n",
        "\n",
        "print(f'Result: y = {a.item()} + {b.item()} * P3({c.item()} + {d.item()} x)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdLZSJjaY2r8"
      },
      "source": [
        "#Q2\n",
        "\"\"\"\n",
        "We will implement many custom kernels. Try to improve the classification accuracy and F-1 scores.\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import sklearn\n",
        "\n",
        "#You must use a random state of 2011 for this homework.\n",
        "clf = SVC(random_state=2011)\n",
        "clf.fit(X, Y)\n",
        "yp = clf.predict(XTe)\n",
        "print(accuracy_score(YTe, yp))\n",
        "print(f1_score(YTe, yp, average='macro'))\n",
        "\n",
        "# The version of sklearn should be \"0.22.2.post1\" for reproducibility.\n",
        "print(sklearn.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}