{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2-2016112083.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVvo3D7wXNP-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2856941-a939-4e60-8602-7688eed59ba7"
      },
      "source": [
        "#Q1\n",
        "\"\"\"\n",
        "We use our custom function to approximate the sine function.\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import math\n",
        "\n",
        "\n",
        "class CustomFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        ctx.save_for_backward(input)\n",
        "        return 0.5 * (5 * input ** 3 - 3 * input)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, = ctx.saved_tensors\n",
        "\n",
        "        # grad_output: Tensor containing gradient of the loss with respect to the output.\n",
        "        # computed the gradient of the loss with respect to the input which means bacward propagation.\n",
        "        return grad_output * 0.5 * (15 * input ** 2 - 3)\n",
        "\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
        "y = torch.sin(x) # We approximate this sine function.\n",
        "\n",
        "# In our model, we have 4 weights to train: y = a + b * P3(c + d * x).\n",
        "# These weights need to be initialized.\n",
        "# Setting requires_grad=True indicates that we want to compute gradients with\n",
        "# respect to these Tensors during the backward pass.\n",
        "a = torch.full((), 0.0, device=device, dtype=dtype, requires_grad=True)\n",
        "b = torch.full((), -1.0, device=device, dtype=dtype, requires_grad=True)\n",
        "c = torch.full((), 0.0, device=device, dtype=dtype, requires_grad=True)\n",
        "d = torch.full((), 0.3, device=device, dtype=dtype, requires_grad=True)\n",
        "\n",
        "learning_rate = 5e-6\n",
        "for t in range(2000):\n",
        "    P3 = CustomFunction.apply\n",
        "\n",
        "    # Forward pass: predict y.\n",
        "    # P3 using our custom backward function.\n",
        "    y_pred = a + b * P3(c + d * x)\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = (y_pred - y).pow(2).sum()\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "    \n",
        "    # Use autograd to compute the backward pass.\n",
        "    loss.backward()\n",
        " \n",
        "    # Update weights using gradient descent\n",
        "    with torch.no_grad():\n",
        "   \n",
        "        a -= learning_rate * a.grad\n",
        "        b -= learning_rate * b.grad\n",
        "        c -= learning_rate * c.grad\n",
        "        d -= learning_rate * d.grad\n",
        "\n",
        "        # Manually zero the gradients after updating weights\n",
        "        a.grad = None\n",
        "        b.grad = None\n",
        "        c.grad = None\n",
        "        d.grad = None\n",
        "\n",
        "print(f'Result: y = {a.item()} + {b.item()} * P3({c.item()} + {d.item()} x)')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99 209.9583282470703\n",
            "199 144.66018676757812\n",
            "299 100.70249938964844\n",
            "399 71.03519439697266\n",
            "499 50.97850799560547\n",
            "599 37.403133392333984\n",
            "699 28.206865310668945\n",
            "799 21.97318458557129\n",
            "899 17.7457275390625\n",
            "999 14.877889633178711\n",
            "1099 12.931764602661133\n",
            "1199 11.610918045043945\n",
            "1299 10.714248657226562\n",
            "1399 10.105474472045898\n",
            "1499 9.692106246948242\n",
            "1599 9.411375045776367\n",
            "1699 9.220745086669922\n",
            "1799 9.091285705566406\n",
            "1899 9.003361701965332\n",
            "1999 8.943639755249023\n",
            "Result: y = 1.106413745344259e-11 + -2.208526849746704 * P3(-6.452179068805464e-11 + 0.2554861009120941 x)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdLZSJjaY2r8",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "60b06d52-c307-4757-86df-53cc3a219875"
      },
      "source": [
        "#Q2\n",
        "\n",
        "\"\"\"\n",
        "We will implement many custom kernels. Try to improve the classification accuracy and F-1 scores.\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "# Upload data\n",
        "uploaded = files.upload()\n",
        "\n",
        "\n",
        "# load data using pandas and cast them to numpy\n",
        "X = pd.read_csv(io.BytesIO(uploaded['trainX.csv']),header = None)\n",
        "Y = pd.read_csv(io.BytesIO(uploaded['trainY.csv']),header = None)\n",
        "XTe = pd.read_csv(io.BytesIO(uploaded['testX.csv']),header = None)\n",
        "YTe = pd.read_csv(io.BytesIO(uploaded['testY.csv']),header = None)\n",
        "X = (X.to_numpy())\n",
        "Y = (Y.to_numpy())\n",
        "XTe = (XTe.to_numpy())\n",
        "YTe = (YTe.to_numpy())\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-aa36eeaf-002c-4f6a-bd58-c2a62bffc55f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-aa36eeaf-002c-4f6a-bd58-c2a62bffc55f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving testX.csv to testX (1).csv\n",
            "Saving testY.csv to testY (1).csv\n",
            "Saving trainX.csv to trainX (1).csv\n",
            "Saving trainY.csv to trainY (1).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eP3UKou1ed5k"
      },
      "source": [
        "# Custom kernels that I implemented\n",
        "\n",
        "def euclid_distance(X1, X2):\n",
        "\n",
        "    # It have two parameter for each dataset.\n",
        "    # It returns Euclid Distance between two dataset matrixes\n",
        "    term1 = (X1 ** 2).sum(axis=1).reshape(-1,1)\n",
        "    term2 = (X2 ** 2).sum(axis=1)\n",
        "    term3 = -2 * np.dot(X1,X2.T)\n",
        "    return np.abs(term1 + term2 - term3)\n",
        "\n",
        "\n",
        "def linear_kernel(X1, X2):\n",
        "    #  Linear kernel : k (xi , xj) = xi . xj \n",
        "    return X1.dot(X2.T)\n",
        "\n",
        "def poly_kernel_homo(X1,X2,degree=2):\n",
        "    #Polynomial (homogeneous) : k(xi,xj) = (xi . xj)^d\n",
        "    return (X1.dot(X2.T)) ** degree\n",
        "\n",
        "def poly_kernel_inhomo(X1,X2,degree=2, c=10):\n",
        "    #Polynomial (homogeneous) : k(xi,xj) = (xi . xj + c)^d\n",
        "    return (X1.dot(X2.T) + c) ** degree\n",
        "\n",
        "def rbf_kernel(X1,X2,gamma = 0.1):\n",
        "    #  Gaussian radial basis function (rbf) : k(xi, yj) = e^(-gamma||xi - yj||^2)\n",
        "    return np.exp(-gamma * euclid_distance(X1,X2))\n",
        "\n",
        "\n",
        "def cosine_kernel(X1,X2):\n",
        "    # Cosine :  K(xi, xj) = xi.xj / (||x|| . ||y||)\n",
        "    term1 = np.sqrt((X1 ** 2).sum(axis=1)).reshape(-1, 1)\n",
        "    term2 = np.sqrt((X2 ** 2).sum(axis=1)).reshape(-1, 1)\n",
        "    return X1.dot(X2.T) / (term1.dot(term2.T))\n",
        "\n",
        "def multiquadric_kernel(X1,X2,c=2):\n",
        "    # multiquadric :    k(xi, yj) = 1 / sqrt(|| xi- yj ||^2 + c^2)\n",
        "    return np.sqrt(euclid_distance(X1,X2) + c ** 2)\n",
        "\n",
        "def cauchy_kernel(X1,X2, sigma= 2):\n",
        "    # cauchy : k(xi, xj) = 1 / (1 + || xi - xj ||^2 / sigma ^ 2)\n",
        "\n",
        "    distance = euclid_distance(X1, X2)\n",
        "    return 1 / (1 + distance / sigma)\n",
        "\n",
        "def tstudent_kernel(X1,X2, d=2):\n",
        "    # tstudent :  k(xi , xj) = 1 / (1 + ||xi - yj||^d)\n",
        "\n",
        "    return 1 / (1 + (euclid_distance(X1,X2) ** d / 2))\n",
        "\n",
        "def log_kernel(X1,X2, d=2):\n",
        "    #  k(xi, xj) = -log(|| xi-xj ||^d) + 1 \n",
        "\n",
        "    return -np.log(euclid_distance(X1, X2) ** d / 2.) + 1\n",
        "\n",
        "def thin_plate_kernel(X1,X2,n=3):\n",
        "    # thin-plate: k(xi, xj) = || xi-xj ||^2n+1\n",
        "    return euclid_distance(X1, X2) ** ((2*n+1) / 2)\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPxDCD0rwabS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e9d0506-e722-410f-83ae-5090acdd46aa"
      },
      "source": [
        "\n",
        "Y= Y.reshape(160,)\n",
        "# apply custom kernels to SVM\n",
        "\n",
        "clf = SVC()\n",
        "clf = SVC(kernel = linear_kernel, random_state=2011)\n",
        "clf.fit(X, Y)\n",
        "yp = clf.predict(XTe)\n",
        "print(\"Linear Kernel DIY\")\n",
        "print(\"AcuuracyScore: \", accuracy_score(YTe, yp))\n",
        "print(\"F1 score: \", f1_score(YTe, yp, average='macro'))\n",
        "print()\n",
        "\n",
        "clf = SVC()\n",
        "clf = SVC(kernel = 'linear', random_state=2011)\n",
        "clf.fit(X, Y)\n",
        "yp = clf.predict(XTe)\n",
        "print(\"Linear Kernel sklearn version\")\n",
        "print(\"AcuuracyScore: \", accuracy_score(YTe, yp))\n",
        "print(\"F1 score: \", f1_score(YTe, yp, average='macro'))\n",
        "print()\n",
        "\n",
        "clf = SVC(kernel = poly_kernel_homo, random_state=2011)\n",
        "clf.fit(X, Y)\n",
        "yp = clf.predict(XTe)\n",
        "print(\"Homo Polynomial Kernel DIY\")\n",
        "print(\"AcuuracyScore: \", accuracy_score(YTe, yp))\n",
        "print(\"F1 score: \", f1_score(YTe, yp, average='macro'))\n",
        "print()\n",
        "\n",
        "clf = SVC(kernel = 'poly', gamma=1,degree=2, coef0=0, random_state=2011)\n",
        "clf.fit(X, Y)\n",
        "yp = clf.predict(XTe)\n",
        "print(\"Homo Polynomial Kernel sklearn version\")\n",
        "print(\"AcuuracyScore: \", accuracy_score(YTe, yp))\n",
        "print(\"F1 score: \", f1_score(YTe, yp, average='macro'))\n",
        "print()\n",
        "\n",
        "clf = SVC(kernel = poly_kernel_inhomo, random_state=2011)\n",
        "clf.fit(X, Y)\n",
        "yp = clf.predict(XTe)\n",
        "print(\"Inhomo Polynomial Kernel DIY\")\n",
        "print(\"AcuuracyScore: \", accuracy_score(YTe, yp))\n",
        "print(\"F1 score: \", f1_score(YTe, yp, average='macro'))\n",
        "print()\n",
        "\n",
        "clf = SVC(kernel = \"poly\",gamma= 1, degree = 2, coef0= 10, random_state=2011)\n",
        "clf.fit(X, Y)\n",
        "yp = clf.predict(XTe)\n",
        "print(\"Inhomo Polynomial Kernel sklearn version\")\n",
        "print(\"AcuuracyScore: \", accuracy_score(YTe, yp))\n",
        "print(\"F1 score: \", f1_score(YTe, yp, average='macro'))\n",
        "print()\n",
        "\n",
        "clf = SVC(kernel = rbf_kernel, random_state=2011)\n",
        "clf.fit(X, Y)\n",
        "yp = clf.predict(XTe)\n",
        "print(\"Gaussian Radial Basis Function Kernel DIY version\")\n",
        "print(\"AcuuracyScore: \", accuracy_score(YTe, yp))\n",
        "print(\"F1 score: \", f1_score(YTe, yp, average='macro'))\n",
        "print()\n",
        "\n",
        "clf = SVC(kernel = 'rbf', gamma = 0.1, random_state=2011)\n",
        "clf.fit(X, Y)\n",
        "yp = clf.predict(XTe)\n",
        "print(\"Gaussian Radial Basis Function Kernel sklearn version\")\n",
        "print(\"AcuuracyScore: \", accuracy_score(YTe, yp))\n",
        "print(\"F1 score: \", f1_score(YTe, yp, average='macro'))\n",
        "print()\n",
        "\n",
        "clf = SVC(kernel = cosine_kernel, random_state=2011)\n",
        "clf.fit(X, Y)\n",
        "yp = clf.predict(XTe)\n",
        "print(\"Cosine Kernel\")\n",
        "print(\"AcuuracyScore: \", accuracy_score(YTe, yp))\n",
        "print(\"F1 score: \", f1_score(YTe, yp, average='macro'))\n",
        "print()\n",
        "\n",
        "clf = SVC(kernel = multiquadric_kernel, random_state=2011)\n",
        "clf.fit(X, Y)\n",
        "yp = clf.predict(XTe)\n",
        "print(\"Multiquadric Kernel\")\n",
        "print(\"AcuuracyScore: \", accuracy_score(YTe, yp))\n",
        "print(\"F1 score: \", f1_score(YTe, yp, average='macro'))\n",
        "print()\n",
        "\n",
        "clf = SVC(kernel = cauchy_kernel, random_state=2011)\n",
        "clf.fit(X, Y)\n",
        "yp = clf.predict(XTe)\n",
        "print(\"Cauchy Kernel\")\n",
        "print(\"AcuuracyScore: \", accuracy_score(YTe, yp))\n",
        "print(\"F1 score: \", f1_score(YTe, yp, average='macro'))\n",
        "print()\n",
        "\n",
        "clf = SVC(kernel = tstudent_kernel, random_state=2011)\n",
        "clf.fit(X, Y)\n",
        "yp = clf.predict(XTe)\n",
        "print(\"Tstudent Kernel\")\n",
        "print(\"AcuuracyScore: \", accuracy_score(YTe, yp))\n",
        "print(\"F1 score: \", f1_score(YTe, yp, average='macro'))\n",
        "print()\n",
        "\n",
        "clf = SVC(kernel = log_kernel, random_state=2011)\n",
        "clf.fit(X, Y)\n",
        "yp = clf.predict(XTe)\n",
        "print(\"Log Kernel\")\n",
        "print(\"AcuuracyScore: \", accuracy_score(YTe, yp))\n",
        "print(\"F1 score: \", f1_score(YTe, yp, average='macro'))\n",
        "print()\n",
        "\n",
        "clf = SVC(kernel = thin_plate_kernel, random_state=2011)\n",
        "clf.fit(X, Y)\n",
        "yp = clf.predict(XTe)\n",
        "print(\"Thin Plate Kernel\")\n",
        "print(\"AcuuracyScore: \", accuracy_score(YTe, yp))\n",
        "print(\"F1 score: \", f1_score(YTe, yp, average='macro'))\n",
        "print()\n",
        "\n",
        "# # The version of sklearn should be \"0.22.2.post1\" for reproducibility.\n",
        "print(sklearn.__version__)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear Kernel DIY\n",
            "AcuuracyScore:  0.375\n",
            "F1 score:  0.323867478025693\n",
            "\n",
            "Linear Kernel sklearn version\n",
            "AcuuracyScore:  0.375\n",
            "F1 score:  0.323867478025693\n",
            "\n",
            "Homo Polynomial Kernel DIY\n",
            "AcuuracyScore:  0.725\n",
            "F1 score:  0.6925227113906359\n",
            "\n",
            "Homo Polynomial Kernel sklearn version\n",
            "AcuuracyScore:  0.725\n",
            "F1 score:  0.6925227113906359\n",
            "\n",
            "Inhomo Polynomial Kernel DIY\n",
            "AcuuracyScore:  0.75\n",
            "F1 score:  0.7252747252747254\n",
            "\n",
            "Inhomo Polynomial Kernel sklearn version\n",
            "AcuuracyScore:  0.75\n",
            "F1 score:  0.7252747252747254\n",
            "\n",
            "Gaussian Radial Basis Function Kernel DIY version\n",
            "AcuuracyScore:  0.65\n",
            "F1 score:  0.6419437340153452\n",
            "\n",
            "Gaussian Radial Basis Function Kernel sklearn version\n",
            "AcuuracyScore:  0.625\n",
            "F1 score:  0.5943204868154158\n",
            "\n",
            "Cosine Kernel\n",
            "AcuuracyScore:  0.5\n",
            "F1 score:  0.494949494949495\n",
            "\n",
            "Multiquadric Kernel\n",
            "AcuuracyScore:  0.425\n",
            "F1 score:  0.3943383805134958\n",
            "\n",
            "Cauchy Kernel\n",
            "AcuuracyScore:  0.55\n",
            "F1 score:  0.53125\n",
            "\n",
            "Tstudent Kernel\n",
            "AcuuracyScore:  0.575\n",
            "F1 score:  0.5682539682539682\n",
            "\n",
            "Log Kernel\n",
            "AcuuracyScore:  0.5\n",
            "F1 score:  0.4666666666666667\n",
            "\n",
            "Thin Plate Kernel\n",
            "AcuuracyScore:  0.55\n",
            "F1 score:  0.52\n",
            "\n",
            "0.22.2.post1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sesnbOvS8nwG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}